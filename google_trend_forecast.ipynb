{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google trend forecast",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGTP/7n21nlhMfEm2wjibC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRBiR2fi2bJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pytrends\n",
        "#!pip install seaborn\n",
        "#!pip install george"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmyT1BnW4mxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from fbprophet import Prophet\n",
        "import george\n",
        "import numpy as np\n",
        "from pytrends.request import TrendReq\n",
        "from pytrends.exceptions import ResponseError\n",
        "from time import sleep\n",
        "import scipy.optimize as op\n",
        "from george import kernels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAx_CtSL7dOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pytrends = TrendReq(hl='en-US', tz=360)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dVjyl3W497m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trend_Forecast:\n",
        "\n",
        "  def __init__(self, keyword, group, loc, year_start, month_start, day_start, year_end, month_end, day_end, num_future_days):\n",
        "    '''\n",
        "    keyword: keyword to be searched on Google\n",
        "    group: the google platform on which the google search take place; options: images, youtube, news\n",
        "    loc: geographical location in which the google searches take place\n",
        "    '''\n",
        "\n",
        "    self.keyword = keyword\n",
        "    self.group = group \n",
        "    self.loc = loc\n",
        "    self.year_start = year_start\n",
        "    self.month_start = month_start \n",
        "    self.day_start = day_start\n",
        "    self.year_end = year_end\n",
        "    self.month_end = month_end \n",
        "    self.day_end = day_end\n",
        "    self.num_future_days = num_future_days\n",
        "\n",
        "  def fetch_from_google(self):\n",
        "\n",
        "    pytrends = TrendReq(hl='en-US', tz=360)\n",
        "    #pytrends.build_payload([self.keyword], cat=0, timeframe='today 5-y', geo='', gprop=self.group)\n",
        "\n",
        "    attempts, collected = 0, False\n",
        "    while not collected:\n",
        "        try:\n",
        "            pytrends.build_payload([self.keyword], cat=0, timeframe='today 5-y', geo='', gprop=self.group)\n",
        "        except ResponseError as err:\n",
        "            print(err)\n",
        "            print(f'Trying again in {40 + 5 * attempts} seconds.')\n",
        "            sleep(40 + 5 * attempts)\n",
        "            attempts += 1\n",
        "            if attempts > 3:\n",
        "                print('Failed after 3 attemps, abort fetching.')\n",
        "                break\n",
        "        else:\n",
        "            collected = True\n",
        "\n",
        "\n",
        "    data = pytrends.get_historical_interest([self.keyword], \n",
        "                                            year_start=self.year_start, month_start=self.month_start, day_start=self.day_start, \n",
        "                                            year_end=self.year_end, month_end=self.month_end, day_end=self.day_end, \n",
        "                                            cat=0, geo='', gprop=self.group, sleep=0)\n",
        "    data.drop(columns=['isPartial'], inplace=True)\n",
        "    daily_data = data.groupby(data.index.date).sum()\n",
        "    daily_data = daily_data[1:-1]\n",
        "    daily_data[self.keyword] = daily_data[self.keyword]/daily_data[self.keyword].max()\n",
        "\n",
        "    return daily_data\n",
        "\n",
        "  def prophet(self):\n",
        "\n",
        "    daily_data = self.fetch_from_google()\n",
        "    prophet_data = daily_data.copy()\n",
        "    prophet_data[\"ds\"] = prophet_data.index\n",
        "    prophet_data[\"y\"] = prophet_data[self.keyword]\n",
        "    prophet_model = Prophet()\n",
        "    prophet_model.fit(prophet_data)\n",
        "    future_data = prophet_model.make_future_dataframe(periods = self.num_future_days)\n",
        "    forecast = prophet_model.predict(future_data)\n",
        "    \n",
        "    yhat = forecast[\"yhat\"]\n",
        "    ylow = forecast[\"yhat_lower\"]\n",
        "    yhigh = forecast[\"yhat_upper\"]\n",
        "    \n",
        "    summary = {\"input time\" : daily_data.index.values, \n",
        "               \"input value\": daily_data[self.keyword].values, \n",
        "               \"output time\": future_data.ds.values,\n",
        "               \"output value\": yhat, \n",
        "               \"output lower\": ylow, \n",
        "               \"output higher\": yhigh}\n",
        "\n",
        "    return summary\n",
        "\n",
        "  def gp_forecast(self):\n",
        "\n",
        "    k2 = 2.4**2 * kernels.ExpSquaredKernel(90**2) * kernels.ExpSine2Kernel(2.0 / 1.3**2, 1.0)\n",
        "    kernel = k2\n",
        "\n",
        "    daily_data = self.fetch_from_google()\n",
        "    daily_data = daily_data.asfreq('D', method='pad')\n",
        "    future_daily_data = daily_data.tshift(self.num_future_days)\n",
        "    \n",
        "    present_time = 2000 + (np.array(daily_data.index.to_julian_date()) - 2451545.0) / 365.25\n",
        "    future_time = 2000 + (np.array(future_daily_data.index.to_julian_date()) - 2451545.0) / 365.25\n",
        "    y = np.array(daily_data[self.keyword])\n",
        "\n",
        "    gp = george.GP(kernel, mean=np.mean(y), fit_mean=True,\n",
        "               white_noise=np.log(0.19**2), fit_white_noise=True)\n",
        "    gp.compute(present_time)\n",
        "    \n",
        "    print(\"current log-likelihood value\", gp.log_likelihood(y))\n",
        "    print(\"current derivative of the log-likelihood \", gp.grad_log_likelihood(y))\n",
        "\n",
        "\n",
        "    def nll(p):\n",
        "      gp.set_parameter_vector(p)\n",
        "      ll = gp.log_likelihood(y, quiet=True)\n",
        "      return -ll if np.isfinite(ll) else 1e25\n",
        "\n",
        "    # And the gradient of the objective function.\n",
        "    def grad_nll(p):\n",
        "      gp.set_parameter_vector(p)\n",
        "      return -gp.grad_log_likelihood(y, quiet=True)\n",
        "\n",
        "    # Run the optimization routine.\n",
        "    p0 = gp.get_parameter_vector()\n",
        "    results = op.minimize(nll, p0, jac=grad_nll, method=\"L-BFGS-B\")\n",
        "\n",
        "    # Update the kernel and print the final log-likelihood.\n",
        "    gp.set_parameter_vector(results.x)\n",
        "\n",
        "    ypred, ycov = gp.predict(y, future_time)\n",
        "    std = np.sqrt(np.diag(ycov))\n",
        "\n",
        "    summary = {\"input time\" : daily_data.index.values, \n",
        "               \"input value\": daily_data[self.keyword].values, \n",
        "               \"output time\": future_daily_data.index.values,\n",
        "               \"output value\": ypred, \n",
        "               \"output lower\": ypred - std, \n",
        "               \"output higher\": ypred + std}\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "  def plot(self, model_choice):\n",
        "\n",
        "    if model_choice == \"prophet\":\n",
        "\n",
        "      summary = self.prophet()\n",
        "\n",
        "    elif model_choice == \"GP\":\n",
        "\n",
        "      summary = self.gp_forecast()\n",
        "\n",
        "    fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (20, 5))\n",
        "    ax.scatter(summary[\"input time\"], summary[\"input value\"], s = 10, color = \"k\", alpha = 0.6)\n",
        "    ax.fill_between(summary[\"output time\"], summary[\"output lower\"], summary[\"output upper\"], alpha = 0.6)\n",
        "    ax.plot(summary[\"output time\"], summary[\"output value\"], linewidth = 2, color = \"C3\")\n",
        "    ax.set_xlabel(\"Time\" , fontsize = 10)\n",
        "    ax.set_ylabel(\"Google trend forecast \"+self.keyword, fontsize = 10)\n",
        "    plt.show()\n",
        "\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PloITJ6Cadk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trend_forecast = Trend_Forecast(keyword  =\"AI\", group = \"images\", loc = \"\", \n",
        "               year_start = 2018, month_start = 1, day_start = 1, \n",
        "               year_end = 2020, month_end = 1, day_end = 1, num_future_days = 20)\n",
        "\n",
        "model_choices = [\"prophet\", \"GP\"]\n",
        "for model in model_choices:\n",
        "\n",
        "  trend_forecast.plot(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BQCm2NZam2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}